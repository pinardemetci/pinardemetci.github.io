 I am a computational biologist, working towards my Ph.D. with Lorin Crawford and Ritambhara Singh. My masters advisor was Sorin Istrail. <br><br>


## <i class="fa fa-chevron-right"></i> Education

<table class="table table-hover">
  <tr>
    <td class="col-md-3">September 2018 - May 2023</td>
    <td>
        <strong>Ph.D. in Computer Science and Computational Biology</strong>
          (0.00/0.00)
        <br>
      Brown University (Providence, RI)
    </td>
  </tr>
  <tr>
    <td class="col-md-3">September 2018 - May 2020</td>
    <td>
        <strong>M.S. in Computer Science</strong>
          (4.00/4.00)
        <br>
      Brown University (Providence, RI)
    </td>
  </tr>
  <tr>
    <td class="col-md-3">September 2013 - May 2017</td>
    <td>
        <strong>B.S. in Bioengineering</strong>
          (3.67/4.00)
        <br>
      Olin College of Engineering (Needham, MA)
    </td>
  </tr>
  <tr>
    <td class="col-md-3">September 2008 - June 2013</td>
    <td>
      TEVITOL High School for Gifted + IB Diploma (Gebze, Turkey)
    </td>
  </tr>
</table>


## <i class="fa fa-chevron-right"></i> Experience
<table class="table table-hover">
<tr>
  <td class='col-md-3'>June 2020 - Sep 2020</td>
  <td><strong>Microsoft Research: Genomics</strong>, Research Intern</td>
</tr>
<tr>
</tr>
<tr>
  <td class='col-md-3'>May 2017 - Sept 2018</td>
  <td><strong>Massachusetts Institute of Technology</strong>, Research Associate</td>
</tr>
<tr>
</tr>
</table>


## <i class="fa fa-chevron-right"></i> Research Projects <a href="https://github.com/bamos/cv/blob/master/publications/selected.bib"><i class="fa fa-code-fork" aria-hidden="true"></i></a>

<a href="https://scholar.google.com/citations?user=d8gdZR4AAAAJ" class="btn btn-primary" style="padding: 0.3em;">
  <i class="ai ai-google-scholar"></i> Google Scholar
</a>

<table class="table table-hover">
<tr>
<td class="col-md-3"><a href='http://web.stanford.edu/~boyd/papers/pdf/diff_cvxpy.pdf' target='_blank'><img src="images/publications/amos2019differentiable3.png"/></a> </td>
<td>
    <strong>Differentiable Convex Optimization Layers</strong><br>
    D. Parker*, <strong>P.Demetci*</strong>, and G.W. Li <br>
     *Equal Contribution<br>
    Journal of Bacteriology, 2019<br>
    
    [1] 
[<a href='javascript:;'
    onclick='$("#abs_parkerdemetci").toggle()'>abs</a>] [<a href='https://jb.asm.org/content/early/2019/07/03/JB.00259-19/figures-only?versioned=true' target='_blank'>pdf</a>] <br>
    
<div id="abs_parkerdemetci" style="text-align: justify; display: none" markdown="1">
We investigated the regulatory network rewiring in single gene knockout strains in E.coli and found that a few different types of mutations (IS element insertions and point mutations in lrhA and fklB) were common in Keio collection. These secondary mutations were accumulated when overnight cultures were not shaken.
</div>

</td>
</tr>



</table>


## <i class="fa fa-chevron-right"></i> Teaching Experience
<table class="table table-hover">
<tr>
  <td class='col-md-1'>S2017</td>
  <td><strong>Advanced Algorithms in Computational Biology and Medical Bioinformatics</strong> (CSCI 2820), TA</td>
</tr>
<tr>
  <td class='col-md-1'>S2016</td>
  <td><strong>Modern Biology: Drug Design</strong> (BIOL ... ), TA</td>
</tr>
</table>


## <i class="fa fa-chevron-right"></i> Honors & Awards
<table class="table table-hover">
<tr>
  <td class='col-md-2'>2016 - 2019</td>
  <td>
   Meritorius Winner: 
    <!--  -->
  </td>
</tr>
<tr>
  <td class='col-md-2'>2011 - 2014</td>
  <td>
   Undergrad Scholarships
    <!--  -->
  </td>
</tr>
</table>


## <i class="fa fa-chevron-right"></i> Service
<table class="table table-hover">
<tr>
  <td class='col-md-2'>Reviewer</td>
  <td markdown="1">
Journal of Bacteriology (December 2019)
  </td>
</tr>
<tr>
  <td class='col-md-2'>Member</td>
  <td markdown="1">
Models, Inference, and Algorithms (MIA) at Broad Institute
  </td>
</tr>
</table>


## <i class="fa fa-chevron-right"></i> Skills
<table class="table table-hover">
<tr>
  <td class='col-md-2'>Languages</td>
  <td markdown="1">
Python, R, Java, C++ </td>
</tr>
<tr>
  <td class='col-md-2'>Frameworks</td>
  <td markdown="1">
NumPy, Pandas, PyTorch, SciPy, TensorFlow, HDF5
  </td>
</tr>
<tr>
  <td class='col-md-2'>Systems</td>
  <td markdown="1">
Linux, OSX
  </td>
</tr>
<tr>
  <td class='col-md-2'>Bioinformatics Tools</td>
  <td markdown="1">
VCFtools, BEDtools
  </td>
</tr>
</table>


## <i class="fa fa-chevron-right"></i> Publications <a href="https://github.com/bamos/cv/blob/master/publications/all.bib"><i class="fa fa-code-fork" aria-hidden="true"></i></a>

<a href="https://scholar.google.com/citations?user=d8gdZR4AAAAJ" class="btn btn-primary" style="padding: 0.3em;">
  <i class="ai ai-google-scholar"></i> Google Scholar
</a>

<h2>2019</h2>
<table class="table table-hover">

<tr>
<td>
    <strong>Differentiable Convex Optimization Layers</strong><br>
    A. Agrawal*, <strong>B. Amos*</strong>, S. Barratt*, S. Boyd*, S. Diamond*, and J. Z. Kolter*<br>
    NeurIPS 2019<br>
    
    [1] 
[<a href='javascript:;'
    onclick='$("#abs_amos2019differentiable3_all_bib").toggle()'>abs</a>] [<a href='http://web.stanford.edu/~boyd/papers/pdf/diff_cvxpy.pdf' target='_blank'>pdf</a>]  [<a href='https://github.com/cvxgrp/cvxpylayers' target='_blank'>code</a>] <br>
    
<div id="abs_amos2019differentiable3_all_bib" style="text-align: justify; display: none" markdown="1">
Recent work has shown how to embed differentiable optimization problems (that is, problems whose solutions can be backpropagated through) as layers within deep learning architectures. This method provides a useful inductive bias for certain problems, but existing software for differentiable optimization layers is rigid and difficult to apply to new settings. In this paper, we propose an approach to differentiating through disciplined convex programs, a subclass of convex optimization problems used by domain-specific languages (DSLs) for convex optimization. We introduce disciplined parametrized programming, a subset of disciplined convex programming, and we show that every disciplined parametrized program can be represented as the composition of an affine map from parameters to problem data, a solver, and an affine map from the solverâ€™s solution to a solution of the original problem (a new form we refer to as affine-solver-affine form). We then demonstrate how to efficiently differentiate through each of these components, allowing for end-to-end analytical differentiation through the entire convex program. We implement our methodology in version 1.1 of CVXPY, a popular Python-embedded DSL for convex optimization, and additionally implement differentiable layers for disciplined convex programs in PyTorch and TensorFlow 2.0. Our implementation significantly lowers the barrier to using convex optimization problems in differentiable programs. We present applications in linear machine learning models and in stochastic control, and we show that our layer is competitive (in execution time) compared to specialized differentiable solvers from past work.
</div>

</td>
</tr>

</table>
